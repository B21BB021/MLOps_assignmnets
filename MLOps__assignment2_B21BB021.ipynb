{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxVBhWcM73vK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import set_config\n",
        "\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip\n",
        "!unzip bike+sharing+dataset.zip"
      ],
      "metadata": {
        "id": "TF080alX-zIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('hour.csv')"
      ],
      "metadata": {
        "id": "dLacgCsL--Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "4katEhd4_PCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['day_night'] = df['hr'].apply(lambda x: 'day' if 6 <= x <= 18 else 'night')\n",
        "df.drop(['instant', 'casual', 'registered', 'atemp',], axis=1, inplace=True)\n",
        "df['dteday'] = pd.to_datetime(df.dteday)\n",
        "df['season'] = df.season.astype('category')\n",
        "df['holiday'] = df.holiday.astype('category')\n",
        "df['weekday'] = df.weekday.astype('category')\n",
        "df['weathersit'] = df.weathersit.astype('category')\n",
        "df['workingday'] = df.workingday.astype('category')\n",
        "df['mnth'] = df.mnth.astype('category')\n",
        "df['yr'] = df.yr.astype('category')\n",
        "df['hr'] = df.hr.astype('category')\n",
        "df.drop(columns=['dteday'], inplace=True)\n",
        "X = df.drop(columns=['cnt'])\n",
        "y = df['cnt']"
      ],
      "metadata": {
        "id": "pBGKVlWz_PyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvvcBjTe_djr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = ['temp', 'hum', 'windspeed']\n",
        "numerical_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy='mean')), # Impute missing values with mean\n",
        "('scaler', MinMaxScaler()) # Normalize using MinMaxScaler\n",
        "])\n",
        "# Transforming above\n",
        "X[numerical_features] = numerical_pipeline.fit_transform(X[numerical_features])\n",
        "# Categorical features\n",
        "categorical_features = ['season', 'weathersit', 'day_night']\n",
        "categorical_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "('onehot', OneHotEncoder(sparse_output=False, drop='first'))\n",
        "])\n",
        "# Transforming above\n",
        "X_encoded = categorical_pipeline.fit_transform(X[categorical_features])"
      ],
      "metadata": {
        "id": "t_rJ80jaBL1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_encoded = pd.DataFrame(\n",
        "    X_encoded,\n",
        "    columns=categorical_pipeline.named_steps['onehot'].get_feature_names_out(categorical_features)\n",
        ")\n",
        "\n",
        "X = pd.concat([X1.drop(columns=categorical_features), X_encoded], axis=1)\n"
      ],
      "metadata": {
        "id": "DoQDPSOlEuNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "EiyWNeZ5Y8Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)"
      ],
      "metadata": {
        "id": "VhVfVvM3Eyhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "pudCHevDFRyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ViBm8PEtFVGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "lStiYhSIFYcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R-squared: {r2}')"
      ],
      "metadata": {
        "id": "L9ipoHEWFcz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "final_pipeline = Pipeline([\n",
        "('num_preprocess', numerical_pipeline),\n",
        "('cat_preprocess', categorical_pipeline),\n",
        "('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "set_config(display='diagram')# To display\n",
        "final_pipeline"
      ],
      "metadata": {
        "id": "k1YiXvJMFgAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('hour.csv')\n"
      ],
      "metadata": {
        "id": "1s-aegTpbU4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iW_BaKGWpWvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['day_night'] = df['hr'].apply(lambda x: 'day' if 6 <= x <= 18 else 'night')\n",
        "df.drop(['instant', 'casual', 'registered', 'atemp',], axis=1, inplace=True)\n",
        "df['dteday'] = pd.to_datetime(df.dteday)\n",
        "df['season'] = df.season.astype('category')\n",
        "df['holiday'] = df.holiday.astype('category')\n",
        "df['weekday'] = df.weekday.astype('category')\n",
        "df['weathersit'] = df.weathersit.astype('category')\n",
        "df['workingday'] = df.workingday.astype('category')\n",
        "df['mnth'] = df.mnth.astype('category')\n",
        "df['yr'] = df.yr.astype('category')\n",
        "df['hr'] = df.hr.astype('category')\n",
        "df.drop(columns=['dteday'], inplace=True)\n",
        "X = df.drop(columns=['cnt'])\n",
        "X1 = df.drop(columns=['cnt'])\n",
        "\n",
        "y = df['cnt']"
      ],
      "metadata": {
        "id": "d_s79M2JbfYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "T4RaXLt-FnWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['temp_hum'] = df['temp'] * df['hum']\n",
        "\n",
        "df['wind_hum'] = df['windspeed'] * df['hum']\n"
      ],
      "metadata": {
        "id": "AqXfFHUXSigd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5S7zEqHjdY5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop(columns=['cnt'])\n",
        "y = df['cnt']\n",
        "x.columns\n"
      ],
      "metadata": {
        "id": "XC2ZPFCVTaRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OBgbD8aHaXUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = ['temp', 'hum', 'windspeed','temp_hum', 'wind_hum' ]\n",
        "numerical_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy='mean')), # Impute missing values with mean\n",
        "('scaler', MinMaxScaler()) # Normalize using MinMaxScaler\n",
        "])\n",
        "# Transforming above\n",
        "x[numerical_features] = numerical_pipeline.fit_transform(x[numerical_features])\n"
      ],
      "metadata": {
        "id": "8Nd6tmByTFER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Categorical features\n",
        "# categorical_features = ['season', 'weathersit', 'day_night']\n",
        "# categorical_pipeline = Pipeline([\n",
        "# ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "# ('onehot', OneHotEncoder(sparse_output=False, drop='first'))\n",
        "# ])\n",
        "# # Transforming above\n",
        "# # print(X[categorical_features])\n",
        "# X_encoded = categorical_pipeline.fit_transform(X1[categorical_features], y)"
      ],
      "metadata": {
        "id": "6uxVyxFHeBYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.head()"
      ],
      "metadata": {
        "id": "dbBWrimWaorr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.info()"
      ],
      "metadata": {
        "id": "0KWFEXaua4LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "ZaEsO3mIbDDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.dtype)\n",
        "print(y.head())\n"
      ],
      "metadata": {
        "id": "pHJlAwMEeIXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.astype(float)\n"
      ],
      "metadata": {
        "id": "863nhPOoeNNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.fillna(y.mean(), inplace=True)  # or any other appropriate strategy\n"
      ],
      "metadata": {
        "id": "VycVBbY-eRkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "ZmRhu0rkeaZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from category_encoders import TargetEncoder\n",
        "categorical_features = ['season', 'weathersit', 'day_night']\n",
        "categorical_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "('target', TargetEncoder())\n",
        "])\n",
        "# Transforming above\n",
        "# print(X[categorical_features])\n",
        "X_encoded = categorical_pipeline.fit_transform(x[categorical_features], y)"
      ],
      "metadata": {
        "id": "DY5JyZ7gXQWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_encoded = pd.DataFrame(\n",
        "    X_encoded,\n",
        "    columns=categorical_pipeline.named_steps['target'].get_feature_names_out(categorical_features)\n",
        ")\n",
        "\n",
        "X = pd.concat([x.drop(columns=categorical_features), X_encoded], axis=1)\n"
      ],
      "metadata": {
        "id": "G-owU2cBTJDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)"
      ],
      "metadata": {
        "id": "B3ZW7KMNTNCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "GhCBygcwTNzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**by scratch**"
      ],
      "metadata": {
        "id": "pLkRwS-hgy93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        self.weights = np.zeros(num_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_predicted = self.sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / num_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return np.array(y_predicted_cls)\n"
      ],
      "metadata": {
        "id": "4V5P1TtVY4OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n"
      ],
      "metadata": {
        "id": "nABzqs0GfTn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run():\n",
        "    # Fit the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred_scratch = model.predict(X_test)\n",
        "    accuracy = np.mean(y_pred_scratch == y_test)\n",
        "\n",
        "    # Print and log metrics\n",
        "    print(f\"Accuracy: {accuracy * 100}%\")\n",
        "    mse = mean_squared_error(y_test, y_pred_scratch)\n",
        "    r2 = r2_score(y_test, y_pred_scratch)\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "    print(f'R-squared: {r2}')\n",
        "\n",
        "    # Log metrics to MLflow\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"mse\", mse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n"
      ],
      "metadata": {
        "id": "BiLyn80TkUg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n"
      ],
      "metadata": {
        "id": "8v8ioURYfumM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn"
      ],
      "metadata": {
        "id": "hNAMePWxfscy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='liblinear', max_iter=100)\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "MYEVL33cqJJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "# Predict and evaluate\n",
        "accuracy = np.mean(y_pred_scratch == y_test)\n",
        "print(f\"Accuracy: {accuracy * 100}%\")\n",
        "mse = mean_squared_error(y_test, y_pred_scratch)\n",
        "r2 = r2_score(y_test, y_pred_scratch)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R-squared: {r2}')\n",
        "# Log metrics to MLflow\n",
        "mlflow.log_metric(\"accuracy\", accuracy)\n",
        "mlflow.log_metric(\"mse\", mse)\n",
        "mlflow.log_metric(\"r2\", r2)"
      ],
      "metadata": {
        "id": "qbPM-ptvNOCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1iTvC1idSCWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the package**"
      ],
      "metadata": {
        "id": "3Xqi1snWhBak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VfiTg_fOfGSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "\n",
        "# Define and train the model\n",
        "X_train.columns = X_train.columns.astype(str)\n",
        "X_test.columns = X_test.columns.astype(str)\n",
        "\n",
        "\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run():\n",
        "\n",
        "    # Log model parameters\n",
        "    mlflow.log_param(\"solver\", \"liblinear\")\n",
        "    mlflow.log_param(\"max_iter\", 100)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"mse\", mse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(model, \"logistic_regression_model\")\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Accuracy: {accuracy * 100}%\")\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "    print(f'R-squared: {r2}')\n",
        "\n",
        "# End the MLflow run (automatically handled by the with statement)\n"
      ],
      "metadata": {
        "id": "Cw3uk73Fghqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}